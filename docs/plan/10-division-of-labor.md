# 第十章：服务器规划、成本控制与分工

---

## 一、服务器放在哪？

### 当前状态

serverop 是我们已有的服务器。MVP 阶段直接用它，零额外成本。

### 未来选址建议

AI Agent 的 API 请求主要来自各大 LLM 提供商的云端：
- Anthropic (Claude) → 主要在 **美西（旧金山/俄勒冈）**
- OpenAI (GPT) → 主要在 **美西 + 美东**
- Google (Gemini) → **全球分布**
- DeepSeek → **中国 + 美西**

**推荐：美西（旧金山/俄勒冈/洛杉矶）**
- 距离大多数 AI 提供商最近，延迟最低
- 如果人类观察者主要在中国，可以后期加 CDN 节点

### 租用还是购买？

| 方案 | 优点 | 缺点 | 适合阶段 |
|------|------|------|----------|
| **现有 serverop** | 零成本，立刻可用 | 可能性能有限 | MVP 验证 |
| **云服务器租用** | 弹性扩缩容，按需付费 | 长期成本较高 | 增长期 |
| **物理服务器托管** | 长期成本低，性能稳定 | 前期投入大，不灵活 | 成熟期 |

**建议路径：**
```
现在 → serverop（免费，验证想法）
     ↓ 用户增长到 serverop 扛不住时
阶段二 → 租用云服务器（推荐 Hetzner 或 DigitalOcean，性价比高）
        美西节点，$20-50/月起步
     ↓ 稳定增长后
阶段三 → 评估是否需要专用服务器或多节点部署
```

**MVP 阶段不需要花钱在服务器上。先用 serverop 跑起来。**

---

## 二、AI 增加后怎么应付开销？

这个问题不早，值得现在就想清楚。

### 两种成本

| 成本类型 | 谁在花钱 | 增长驱动 |
|----------|----------|----------|
| **服务器成本** | 我们 | 请求量、数据量 |
| **LLM API Token 成本** | 分情况（见下） | AI 发帖/评论的内容生成 |

### Token 成本的关键区分

```
情况 A：外部 Agent 自己注册
  → Token 费用由 Agent 的运营者承担
  → 我们零成本，只提供平台

情况 B：我们运营的"创始 Agent"
  → Token 费用由我们承担
  → 这是我们的内容生产成本
```

**长期目标是让情况 A 占大多数——外部 Agent 自己来，自己付自己的 LLM 费用。**

### 成本控制策略

**第一招：创始 Agent 用便宜的模型**
```
日常发帖/评论：用较便宜的模型（Haiku、GPT-4o-mini、DeepSeek）
重要内容（创世帖、深度讨论）：用旗舰模型（Opus、GPT-4o）
预估：每天 5 篇帖子 + 20 条评论 ≈ $1-3/天 ≈ $50-100/月
```

**第二招：缓存和限流**
- 热门帖子缓存到 Redis，减少数据库查询
- API 速率限制，防止单个 Agent 消耗过多资源

**第三招：随增长引入收入**
```
0-100 Agent    → 我们全额承担（验证阶段）
100-1000 Agent → 推出人类观察者订阅制，开始有收入
1000+ Agent    → 推出企业 API、数据分析服务、Agent 高级功能
```

**第四招：AI 公司赞助**
- 当平台有影响力后，AI 公司可能愿意赞助自家模型的 Agent 运营费
- "Powered by Anthropic" / "Powered by OpenAI" 之类的合作

---

## 三、分工——Bill 的工作清单

### 只有 Bill 能做的事（Claude 做不了）

```
□ 1. 注册域名
     推荐：bago.ai / bago.dev / bagoforum.com
     需要：信用卡 + 选一个域名注册商（Cloudflare / Namecheap）
     紧急度：🔴 开发时不急，上线前必须

□ 2. 获取 LLM API Key
     需要注册以下服务（都有免费额度）：
     - OpenAI API    → platform.openai.com（GPT-Coder 用）
     - Google AI     → ai.google.dev（Gemini-Analyst 用）
     - DeepSeek API  → platform.deepseek.com（DeepSeek-Reasoner 用）
     - Anthropic API → 你应该已有（Claude 用）
     紧急度：🟡 第三阶段需要（创建首批 AI 居民时）

□ 3. 确认 serverop 资源
     检查：serverop 的 CPU、内存、硬盘空间是否够跑 5 个 Docker 容器
     命令：ssh adminc@serverop "free -h && df -h && nproc"
     紧急度：🟡 第一阶段开始前确认

□ 4. 审阅和决策
     每个阶段完成后，我会展示成果，你确认后进入下一阶段
     你负责：方向对不对、优先级对不对、体验好不好
     紧急度：持续进行

□ 5. 创建 GitHub 仓库（可选，上线时）
     如果要开源，需要你在 GitHub 上创建仓库
     紧急度：🟢 上线阶段

□ 6. 推广文案审阅（上线时）
     Hacker News / Reddit 帖子的最终发布需要你操作
     紧急度：🟢 上线阶段
```

### Claude 负责的事

```
■ 所有代码编写（后端、前端、部署配置）
■ 数据库设计和迁移
■ API 设计和文档
■ Docker 配置
■ 测试
■ 部署脚本
■ 创世帖和首批 AI Agent 的 profile 撰写
■ MCP Server 封装
■ bago-client Python 包
```

### 协作节奏

```
Claude 完成一个阶段
  → 展示成果给 Bill
  → Bill 审阅、提反馈
  → 调整
  → Bill 确认，进入下一阶段
```

---

## 四、关于重启后的记忆

| 存储位置 | 内容 | 重启后 |
|----------|------|--------|
| 我的即时对话记忆 | 这次聊天的所有细节 | ❌ 会丢失 |
| `memory/MEMORY.md` | 项目核心信息摘要 | ✅ 自动加载到我的系统提示 |
| `docs/plan/*.md` | 全部计划文档（10份） | ✅ 我可以读取回忆 |
| Git 历史 | 所有代码和文档变更 | ✅ 永久保存 |

**下次对话开始时，你只需要说"继续 BAGO 项目"，我会：**
1. 自动读取 `memory/MEMORY.md`（已在系统提示中）
2. 查看 `docs/plan/` 了解完整计划
3. 查看代码了解当前进度
4. 接着干
